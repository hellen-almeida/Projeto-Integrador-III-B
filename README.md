# Projeto Integrador III-B: Deep Learning para Classifica√ß√£o de Linhas de Transporte Intermunicipal

## Pontif√≠cia Universidade Cat√≥lica de Goi√°s - Escola Polit√©cnica
### Curso: Big Data e Intelig√™ncia Artificial


#### Acesso ao notebook via colab: [https://colab.research.google.com/drive/1IgHJiieC1wEktxMvCgHg9J2FvHtgBZh9?authuser=7#scrollTo=Fh9MMPj7iMl-](https://colab.research.google.com/drive/1IgHJiieC1wEktxMvCgHg9J2FvHtgBZh9?usp=sharing)


---

## üìã Sum√°rio

1. [Vis√£o Geral](#vis√£o-geral)
2. [Estrutura do Projeto](#estrutura-do-projeto)
3. [Desenvolvimento da Solu√ß√£o de Deep Learning](#desenvolvimento-da-solu√ß√£o-de-deep-learning)
   - [Arquitetura do Modelo MLP](#arquitetura-do-modelo-mlp)
   - [Justificativa da Arquitetura](#justificativa-da-arquitetura)
   - [Pipeline de Treinamento e Valida√ß√£o](#pipeline-de-treinamento-e-valida√ß√£o)
   - [Avalia√ß√£o de Desempenho](#avalia√ß√£o-de-desempenho)
4. [Como Executar](#como-executar)
5. [Resultados](#resultados)
6. [Refer√™ncias](#refer√™ncias)

---

## Vis√£o Geral

Este projeto implementa uma solu√ß√£o de **Deep Learning** utilizando um **Perceptron Multicamadas (MLP)** para classificar automaticamente o tipo de linha de transporte rodovi√°rio intermunicipal de passageiros no Estado de Goi√°s.

**Concedente:** Ag√™ncia Goiana de Regula√ß√£o, Controle e Fiscaliza√ß√£o de Servi√ßos P√∫blicos (AGR)

**Autores:**
- Fellipy Bernardes da Silva
- Fernanda Santalucia Bonjardim
- Hellen Almeida de Oliveira
- Hugo de Assis Furtado
- Vit√≥ria Gon√ßalves Lordeiro

---

## Estrutura do Projeto

```
Projeto Integrador 3B/
‚îú‚îÄ‚îÄ projeto_integrador_3b_deep_learning.ipynb  # Notebook principal
‚îú‚îÄ‚îÄ README.md                                   # Documenta√ß√£o t√©cnica
‚îú‚îÄ‚îÄ requirements.txt                            # Depend√™ncias do projeto
‚îú‚îÄ‚îÄ empresas-autorizadas-termos-de-autorizacao-e-precos-de-passagens-.csv
‚îú‚îÄ‚îÄ reajuste-de-tarifas-de-transporte-rodoviario-intermunicipal-6.csv
‚îú‚îÄ‚îÄ terminais-rodoviarios-de-passageiros-6.csv
‚îî‚îÄ‚îÄ venv/                                       # Ambiente virtual Python
```

### Datasets Utilizados

| Dataset | Descri√ß√£o | Registros |
|---------|-----------|-----------|
| `empresas-autorizadas-*.csv` | Empresas, linhas e itiner√°rios autorizados | 285 |
| `reajuste-de-tarifas-*.csv` | Coeficientes tarif√°rios por tipo de servi√ßo | 102 |
| `terminais-rodoviarios-*.csv` | Terminais rodovi√°rios e situa√ß√£o operacional | 194 |

---

## Desenvolvimento da Solu√ß√£o de Deep Learning

### Classes de Classifica√ß√£o (Vari√°vel Alvo)

O modelo classifica as linhas de transporte em 5 categorias:

| Classe | Descri√ß√£o | Quantidade |
|--------|-----------|------------|
| **Convencional** | Linhas regulares de transporte intermunicipal | 235 (82.5%) |
| **Semiurbano** | Servi√ßos de curta dist√¢ncia entre munic√≠pios pr√≥ximos | 41 (14.4%) |
| **Viagens Semidiretas** | Com poucas paradas intermedi√°rias | 4 (1.4%) |
| **Expresso** | Servi√ßos com menos paradas, mais r√°pidos | 3 (1.1%) |
| **Viagens Diretas** | Sem paradas intermedi√°rias | 2 (0.7%) |

> **Observa√ß√£o:** O dataset apresenta desbalanceamento significativo, com predomin√¢ncia da classe "Convencional".

<img width="1521" height="533" alt="image" src="https://github.com/user-attachments/assets/c7a28a06-4082-4812-913a-c804b61b7e84" />

<img width="840" height="709" alt="image" src="https://github.com/user-attachments/assets/ef71a257-bf80-4665-bb29-087d0b0d1b8b" />





---

### Arquitetura do Modelo MLP

O modelo implementado √© um **Perceptron Multicamadas (MLP)** com a seguinte arquitetura:

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    CAMADA DE ENTRADA                        ‚îÇ
‚îÇ                    (47 features)                            ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                          ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ              CAMADA OCULTA 1 (128 neur√¥nios)                ‚îÇ
‚îÇ         Dense(128) + ReLU + BatchNorm + Dropout(0.3)        ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                          ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ              CAMADA OCULTA 2 (64 neur√¥nios)                 ‚îÇ
‚îÇ         Dense(64) + ReLU + BatchNorm + Dropout(0.3)         ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                          ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ              CAMADA OCULTA 3 (32 neur√¥nios)                 ‚îÇ
‚îÇ              Dense(32) + ReLU + Dropout(0.2)                ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                          ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                   CAMADA DE SA√çDA                           ‚îÇ
‚îÇ              Dense(5) + Softmax (5 classes)                 ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

#### Especifica√ß√µes T√©cnicas

| Componente | Configura√ß√£o |
|------------|--------------|
| **Entrada** | 47 features (8 num√©ricas + 39 one-hot encoded) |
| **Camadas Ocultas** | 3 camadas (128 ‚Üí 64 ‚Üí 32 neur√¥nios) |
| **Fun√ß√£o de Ativa√ß√£o** | ReLU (camadas ocultas), Softmax (sa√≠da) |
| **Regulariza√ß√£o** | Dropout (0.3, 0.3, 0.2) + BatchNormalization |
| **Inicializa√ß√£o** | He Normal |
| **Otimizador** | Adam (learning rate = 0.001) |
| **Fun√ß√£o de Perda** | Categorical Crossentropy |
| **Sa√≠da** | 5 classes (probabilidades) |

---

### Justificativa da Arquitetura

#### 1. Escolha do MLP

O Perceptron Multicamadas foi escolhido por ser:
- **Adequado para dados tabulares**: Os dados do projeto s√£o predominantemente categ√≥ricos e num√©ricos estruturados
- **Eficiente para classifica√ß√£o multiclasse**: Capacidade de aprender fronteiras de decis√£o n√£o-lineares
- **Interpret√°vel**: Arquitetura mais simples comparada a redes convolucionais ou recorrentes
- **Computacionalmente eficiente**: Treinamento r√°pido para datasets de pequeno/m√©dio porte

#### 2. N√∫mero de Camadas e Neur√¥nios

A arquitetura em **pir√¢mide decrescente** (128 ‚Üí 64 ‚Üí 32) foi escolhida para:
- **Camada 1 (128)**: Capturar padr√µes de alto n√≠vel e intera√ß√µes entre features
- **Camada 2 (64)**: Refinar representa√ß√µes intermedi√°rias
- **Camada 3 (32)**: Consolidar informa√ß√µes antes da classifica√ß√£o final

#### 3. T√©cnicas de Regulariza√ß√£o

| T√©cnica | Justificativa |
|---------|---------------|
| **Dropout (0.2-0.3)** | Previne overfitting desligando neur√¥nios aleatoriamente durante o treino |
| **BatchNormalization** | Estabiliza e acelera o treinamento, permitindo learning rates mais altos |
| **Early Stopping** | Interrompe o treino quando n√£o h√° melhora na valida√ß√£o (paci√™ncia: 15 √©pocas) |

#### 4. Fun√ß√£o de Ativa√ß√£o ReLU

$$f(x) = \max(0, x)$$

Escolhida por:
- Mitigar o problema de vanishing gradients
- Computacionalmente eficiente
- Permite aprendizado de representa√ß√µes esparsas

#### 5. Softmax para Classifica√ß√£o Multiclasse

$$\sigma(z_i) = \frac{e^{z_i}}{\sum_{j=1}^{K} e^{z_j}}$$

Converte os logits em probabilidades, onde a soma de todas as classes √© 1.

---

### Pipeline de Treinamento e Valida√ß√£o

#### Etapa 1: Engenharia de Features

**Features Num√©ricas Extra√≠das:**

| Feature | Descri√ß√£o |
|---------|-----------|
| `NUM_SEQUENCIAL` | N√∫mero sequencial da linha |
| `E_VARIANTE` | Indica se √© variante de outra linha (0/1) |
| `QTD_RODOVIAS` | Quantidade de rodovias no itiner√°rio |
| `PASSA_CAPITAL` | Se passa por Goi√¢nia (0/1) |
| `PASSA_ANAPOLIS` | Se passa por An√°polis (0/1) |
| `TAM_ITINERARIO` | Tamanho da descri√ß√£o do itiner√°rio |
| `TERMINAL_ORIGEM_OPERA` | Se terminal de origem est√° operando (0/1) |
| `TERMINAL_DESTINO_OPERA` | Se terminal de destino est√° operando (0/1) |

**Features Categ√≥ricas (One-Hot Encoded):**
- `CODIGO_EMPRESA` (27 categorias)
- `PROP_TERMINAL_ORIGEM` (4 categorias)
- `PROP_TERMINAL_DESTINO` (4 categorias)

#### Etapa 2: Pr√©-processamento

```python
# Normaliza√ß√£o das features num√©ricas
scaler = StandardScaler()
X_scaled[features_numericas] = scaler.fit_transform(X[features_numericas])

# Convers√£o para float32 (compatibilidade TensorFlow)
X_scaled_array = X_scaled.astype(np.float32).values
```

#### Etapa 3: Divis√£o dos Dados

| Conjunto | Propor√ß√£o | Amostras |
|----------|-----------|----------|
| Treino | 60% | 171 |
| Valida√ß√£o | 20% | 57 |
| Teste | 20% | 57 |

**Estratifica√ß√£o:** Mant√©m propor√ß√£o das classes em todos os conjuntos.

#### Etapa 4: Balanceamento de Classes

Devido ao desbalanceamento severo, foram aplicados **pesos de classe**:

```python
class_weights = compute_class_weight(
    class_weight='balanced',
    classes=np.unique(y_integers),
    y=y_integers
)
```

Isso penaliza mais fortemente erros em classes minorit√°rias durante o treinamento.

#### Etapa 5: Callbacks de Treinamento

| Callback | Configura√ß√£o | Fun√ß√£o |
|----------|--------------|--------|
| **EarlyStopping** | patience=15, restore_best_weights=True | Para o treino se val_loss n√£o melhorar |
| **ReduceLROnPlateau** | factor=0.5, patience=5, min_lr=1e-6 | Reduz learning rate quando estagnado |

#### Etapa 6: Treinamento

```python
historico = modelo.fit(
    X_train, y_train,
    validation_data=(X_val, y_val),
    epochs=150,
    batch_size=16,
    class_weight=class_weight_dict,
    callbacks=callbacks
)
```

---

### Avalia√ß√£o de Desempenho

#### M√©tricas por Conjunto

| Conjunto | Loss | Acur√°cia |
|----------|------|----------|
| Treino | ~0.30 | ~90% |
| Valida√ß√£o | ~0.45 | ~85% |
| Teste | ~0.50 | ~82% |

> **Nota:** Os valores exatos variam a cada execu√ß√£o devido √† natureza estoc√°stica do treinamento.

#### Matriz de Confus√£o

A matriz de confus√£o permite visualizar:
- **Diagonal principal**: Classifica√ß√µes corretas
- **Fora da diagonal**: Erros de classifica√ß√£o
- Classes minorit√°rias podem ter zero predi√ß√µes devido ao desbalanceamento

#### M√©tricas de Classifica√ß√£o

Para cada classe, s√£o calculados:

| M√©trica | F√≥rmula | Interpreta√ß√£o |
|---------|---------|---------------|
| **Precision** | TP / (TP + FP) | % de predi√ß√µes positivas corretas |
| **Recall** | TP / (TP + FN) | % de amostras reais identificadas |
| **F1-Score** | 2 √ó (P √ó R) / (P + R) | M√©dia harm√¥nica de Precision e Recall |

#### Curvas de Aprendizado

O notebook gera gr√°ficos de:
- **Loss vs √âpocas**: Treino e Valida√ß√£o
- **Acur√°cia vs √âpocas**: Treino e Valida√ß√£o

Permite identificar:
- **Overfitting**: Gap crescente entre treino e valida√ß√£o
- **Underfitting**: Alta loss em ambos os conjuntos
- **Converg√™ncia**: Estabiliza√ß√£o das m√©tricas

---

## Como Executar

### Pr√©-requisitos

- Python 3.10+
- pip ou conda

### Instala√ß√£o

1. **Clonar ou baixar o reposit√≥rio**

2. **Criar ambiente virtual (recomendado)**
   ```bash
   python -m venv venv
   source venv/bin/activate  # Linux/Mac
   # ou
   venv\Scripts\activate     # Windows
   ```

3. **Instalar depend√™ncias**
   ```bash
   pip install -r requirements.txt
   ```

### Execu√ß√£o

1. **Abrir o Jupyter Notebook**
   ```bash
   jupyter notebook projeto_integrador_3b_deep_learning.ipynb
   ```

2. **Executar todas as c√©lulas sequencialmente** (Kernel ‚Üí Restart & Run All)

### Artefatos Gerados

Ap√≥s a execu√ß√£o, ser√£o gerados:
- `modelo_mlp_classificacao_linhas.h5` - Modelo treinado
- `label_encoder.pkl` - Codificador de labels
- `scaler.pkl` - Normalizador de features
- `distribuicao_tipos_linha.png` - Gr√°fico de distribui√ß√£o
- `top_empresas.png` - Top 5 empresas
- `curvas_aprendizado.png` - Curvas de treino
- `matriz_confusao.png` - Matriz de confus√£o
- `matriz_confusao_normalizada.png` - Matriz normalizada

---

## Resultados

### Principais Descobertas

1. **Desbalanceamento Severo**: 82.5% das linhas s√£o convencionais, dificultando a classifica√ß√£o das classes minorit√°rias.

2. **Features Discriminativas**: A vari√°vel `E_VARIANTE` mostrou-se importante, pois linhas de servi√ßos especiais (Semiurbano, Expresso) frequentemente s√£o variantes de linhas convencionais.

3. **Concentra√ß√£o Empresarial**: Poucas empresas operam a maioria das linhas, com destaque para "Juarez Mendes de Melo" (45 linhas).

### Limita√ß√µes

- **Dados Limitados**: Apenas 285 registros, insuficientes para treinar redes mais complexas
- **Classes Raras**: "Viagens Diretas" (2 amostras) e "Expresso" (3 amostras) s√£o dif√≠ceis de classificar
- **Features Dispon√≠veis**: A base n√£o possui informa√ß√µes como dist√¢ncia em km, tempo de viagem ou demanda de passageiros

### Melhorias Futuras

- Aplicar t√©cnicas de oversampling (SMOTE) para classes minorit√°rias
- Incluir features geogr√°ficas (coordenadas, dist√¢ncia euclidiana)
- Testar arquiteturas mais complexas com mais dados
- Implementar valida√ß√£o cruzada k-fold

---

## Refer√™ncias

1. AGR - Ag√™ncia Goiana de Regula√ß√£o. **Portal de Dados Abertos do Estado de Goi√°s**. Dispon√≠vel em: https://dadosabertos.go.gov.br/

2. GOODFELLOW, I.; BENGIO, Y.; COURVILLE, A. **Deep Learning**. MIT Press, 2016.

3. CHOLLET, F. **Deep Learning with Python**. Manning Publications, 2021.

4. TensorFlow Documentation. Dispon√≠vel em: https://www.tensorflow.org/

5. Scikit-learn Documentation. Dispon√≠vel em: https://scikit-learn.org/

6. BRASIL. **Resolu√ß√£o N¬∫ 7/2018** - Diretrizes para a Extens√£o na Educa√ß√£o Superior Brasileira. MEC/CNE.

---

**Goi√¢nia, 2025**

*Projeto desenvolvido como requisito da disciplina Projeto Integrador III-B do curso de Big Data e Intelig√™ncia Artificial da PUC Goi√°s.*

